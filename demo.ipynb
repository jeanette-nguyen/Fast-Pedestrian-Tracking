{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import  absolute_import\n",
    "# though cupy is not used but without this line, it raise errors...\n",
    "import cupy as cp\n",
    "import os\n",
    "\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.config import opt\n",
    "from data.dataset import Dataset, TestDataset, inverse_normalize\n",
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "from torch.utils import data as data_\n",
    "import torch\n",
    "from trainer import FasterRCNNTrainer\n",
    "from utils import array_tool as at\n",
    "from utils.vis_tool import vis_bbox\n",
    "from utils.eval_tool import eval_detection_voc\n",
    "\n",
    "# fix for ulimit\n",
    "# https://github.com/pytorch/pytorch/issues/973#issuecomment-346405667\n",
    "import resource\n",
    "\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            with tqdm(unit='B', unit_scale=True, unit_divisor=1024) as bar:\n",
    "                for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                    if chunk:  # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "                        bar.update(CHUNK_SIZE)\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Models from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")\n",
    "\n",
    "# Download Baseline Model\n",
    "download_file_from_google_drive(\"1GyttG9S55QsK3FuXqNof866OdHiwW7R6\", \"./checkpoints/fasterrcnn_set00\")\n",
    "# Download Pruned Network\n",
    "download_file_from_google_drive(\"121OCJTAcFt-9l5XZeiFOIuxGOOHN9typ\", \"./checkpoints/fasterrcnn_set00pruned\")\n",
    "# Download SparseDense Network (WeightSharing Applied)\n",
    "download_file_from_google_drive(\"1TrB631H3LNxHBRMAKIrpSCnVYIU_V-uL\", \"./checkpoints/sparsedense_fasterrcnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    opt._parse(kwargs)\n",
    "    return opt\n",
    "\n",
    "# Input data directory and path to model\n",
    "# Use Baseline Model\n",
    "opt = train(voc_data_dir='dataset', load_path='./checkpoints/fasterrcnn_set00')\n",
    "\n",
    "# Use Pruned Model\n",
    "#opt = train(voc_data_dir='dataset', load_path='./checkpoints/fasterrcnn_set00pruned')\n",
    "\n",
    "# Use SparseDense Model\n",
    "# opt = train(voc_data_dir='dataset', load_path='./checkpoints/sparsedense_fasterrcnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User arguments\n",
    "#print(opt._parse_all())\n",
    "\n",
    "# Load dataset\n",
    "dataset = TestDataset(opt, split='val')\n",
    "dataloader = data_.DataLoader(dataset,\n",
    "                                   batch_size=1,\n",
    "                                   num_workers=opt.test_num_workers,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True\n",
    "                                   )\n",
    "\n",
    "# Construct model\n",
    "faster_rcnn = FasterRCNNVGG16(mask=opt.mask)\n",
    "trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "trainer.load(opt.load_path)\n",
    "\n",
    "# Predict\n",
    "imgs, sizes, gt_bboxes_, gt_labels_ = next(iter(dataloader))\n",
    "sizes = [sizes[0][0].item(), sizes[1][0].item()]\n",
    "pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs,[sizes])\n",
    "\n",
    "# Show score\n",
    "ori_img_ = inverse_normalize(at.tonumpy(imgs[0]))\n",
    "gt_img = vis_bbox(ori_img_,\n",
    "                     at.tonumpy(gt_bboxes_[0]),\n",
    "                     at.tonumpy(gt_labels_[0]))\n",
    "plt.show()\n",
    "\n",
    "pred_img = vis_bbox(ori_img_,\n",
    "                    at.tonumpy(pred_bboxes_[0]),\n",
    "                    at.tonumpy(pred_labels_[0]).reshape(-1),\n",
    "                    at.tonumpy(pred_scores_[0])\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
