{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======user config========\n",
      "{'benchmark_path': None,\n",
      " 'caffe_pretrain': False,\n",
      " 'caffe_pretrain_path': 'checkpoints/vgg16_caffe.pth',\n",
      " 'data': 'voc',\n",
      " 'debug_file': '/tmp/debugf',\n",
      " 'env': 'faster_rcnn',\n",
      " 'epoch': 14,\n",
      " 'load_path': None,\n",
      " 'lr': 0.001,\n",
      " 'lr_decay': 0.1,\n",
      " 'mask': True,\n",
      " 'mask_conv': False,\n",
      " 'mask_lin': True,\n",
      " 'max_size': 1000,\n",
      " 'min_size': 600,\n",
      " 'model_name': 'test_run',\n",
      " 'num_workers': 4,\n",
      " 'plot_every': 40,\n",
      " 'port': 8097,\n",
      " 'pretrained_model': 'vgg16',\n",
      " 'roi_sigma': 1.0,\n",
      " 'rpn_sigma': 3.0,\n",
      " 'sparse_dense': False,\n",
      " 'test_num': 10000,\n",
      " 'test_num_workers': 4,\n",
      " 'use_adam': True,\n",
      " 'use_chainer': False,\n",
      " 'use_drop': False,\n",
      " 'use_simple': False,\n",
      " 'voc_data_dir': '/datasets/home/98/898/cjgunthe/Fast-Pedestrian-Tracking/dataset/',\n",
      " 'weight_decay': 0.0005}\n",
      "==========end============\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9ae0ca8c126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e9ae0ca8c126>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "def eval(dataloader, faster_rcnn, test_num=10000):\n",
    "    print(\"\\nEVAL\")\n",
    "    pred_bboxes, pred_labels, pred_scores = list(), list(), list()\n",
    "    gt_bboxes, gt_labels = list(), list()\n",
    "    for ii, (imgs, sizes, gt_bboxes_, gt_labels_) in tqdm(enumerate(dataloader)):\n",
    "        sizes = [sizes[0][0].item(), sizes[1][0].item()]\n",
    "        pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs, [sizes])\n",
    "        gt_bboxes += list(gt_bboxes_.numpy())\n",
    "        gt_labels += list(gt_labels_.numpy())\n",
    "        pred_bboxes += pred_bboxes_\n",
    "        pred_labels += pred_labels_\n",
    "        pred_scores += pred_scores_\n",
    "        if ii == test_num: break\n",
    "\n",
    "    result = eval_detection_voc(\n",
    "        pred_bboxes, pred_labels, pred_scores,\n",
    "        gt_bboxes, gt_labels, use_07_metric=True)\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    valset = TestDataset(opt,split='val')\n",
    "    val_dataloader = data_.DataLoader(valset,\n",
    "                                batch_size=1,\n",
    "                                num_workers=opt.test_num_workers,\n",
    "                                shuffle=True,\n",
    "                                pin_memory=True\n",
    "                                )\n",
    "    \n",
    "    testset = TestDataset(opt, split='test')\n",
    "    test_dataloader = data_.DataLoader(testset,\n",
    "                                    batch_size=1,\n",
    "                                    num_workers=opt.test_num_workers,\n",
    "                                    shuffle=False,\n",
    "                                    pin_memory=True\n",
    "                                    )\n",
    "    \n",
    "    print(f\"VAL SET: {len(val_dataloader)} | TEST SET: {len(test_dataloader)}\")\n",
    "    print(\"Using Mask VGG\") if opt.mask else print(\"Using normal VGG16\")\n",
    "    faster_rcnn = FasterRCNNVGG16(mask=opt.mask)\n",
    "    print('model construct completed')\n",
    "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "    best_map = 0\n",
    "    lr_ = opt.lr\n",
    "    \n",
    "    if args.path:\n",
    "        assert os.path.isfile(args.path), 'Checkpoint {} does not exist.'.format(args.path)\n",
    "        checkpoint = torch.load(args.path)['other_info']\n",
    "        best_map = checkpoint['best_map']\n",
    "        trainer.load(args.path)\n",
    "        \n",
    "        # if using simple-fast pretrained network, no epoch # saved\n",
    "        # if args.path == :\n",
    "        #     checkpoint['epoch'] = 0\n",
    "        #     best_map = 0\n",
    "        #\n",
    "        checkpoint['epoch'] = 0\n",
    "        print(\"=\"*30+\"   Checkpoint   \"+\"=\"*30)\n",
    "        print(\"Loaded checkpoint '{}' (epoch {})\".format(args.path, checkpoint['epoch']))\n",
    "\n",
    "        # eval_result = eval(val_dataloader, faster_rcnn, test_num=1000)\n",
    "        # lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "        # log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_), str(eval_result['map']),\n",
    "        #                                                    str(trainer.get_meter_data()))\n",
    "        # print(\"Evaluation Results on Validation Set: \")\n",
    "        # print(log_info)\n",
    "\n",
    "\n",
    "        test_eval_result = eval(test_dataloader, faster_rcnn, test_num=1000)\n",
    "        test_lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "        test_log_info = 'lr:{}, map:{}'.format(str(test_lr_), str(test_eval_result['map']))\n",
    "        print(\"Evaluation Results on Test Set of size 1000: \")\n",
    "        print(test_log_info)\n",
    "        print(\"\\n\\n\")\n",
    "    else:\n",
    "        print(\"No checkpoint to evaluate is specified\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    print(opt._parse_all())\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/98/898/cjgunthe/Fast-Pedestrian-Tracking/utils/vis_tool.py:8: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-bd81c9ee953f>\", line 9, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  absolute_import\n",
    "# though cupy is not used but without this line, it raise errors...\n",
    "import cupy as cp\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.config import opt\n",
    "from data.dataset import Dataset, TestDataset, inverse_normalize\n",
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "from torch.utils import data as data_\n",
    "import torch\n",
    "from trainer import FasterRCNNTrainer\n",
    "from utils import array_tool as at\n",
    "from utils.vis_tool import visdom_bbox\n",
    "from utils.eval_tool import eval_detection_voc\n",
    "\n",
    "# fix for ulimit\n",
    "# https://github.com/pytorch/pytorch/issues/973#issuecomment-346405667\n",
    "import resource\n",
    "\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dataloader, faster_rcnn, test_num=10000):\n",
    "    print(\"\\nEVAL\")\n",
    "    pred_bboxes, pred_labels, pred_scores = list(), list(), list()\n",
    "    gt_bboxes, gt_labels = list(), list()\n",
    "    for ii, (imgs, sizes, gt_bboxes_, gt_labels_) in tqdm(enumerate(dataloader)):\n",
    "        sizes = [sizes[0][0].item(), sizes[1][0].item()]\n",
    "        pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs, [sizes])\n",
    "        gt_bboxes += list(gt_bboxes_.numpy())\n",
    "        gt_labels += list(gt_labels_.numpy())\n",
    "        pred_bboxes += pred_bboxes_\n",
    "        pred_labels += pred_labels_\n",
    "        pred_scores += pred_scores_\n",
    "        if ii == test_num: break\n",
    "\n",
    "    result = eval_detection_voc(\n",
    "        pred_bboxes, pred_labels, pred_scores,\n",
    "        gt_bboxes, gt_labels, use_07_metric=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, faster_rcnn, dataloader,  val_dataloader,\n",
    "          test_dataloader, trainer, lr_, best_map, start_epoch):\n",
    "    for epoch in range(start_epoch, start_epoch+opt.epoch):\n",
    "        trainer.reset_meters()\n",
    "        pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for ii, (img, bbox_, label_, scale) in pbar:\n",
    "            # Currently configured to predict (y_min, x_min, y_max, x_max)\n",
    "#             bbox_tmp = bbox_.clone()\n",
    "#             bbox_ = transform_bbox(bbox_)\n",
    "            scale = at.scalar(scale)\n",
    "            \n",
    "            img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "            losses = trainer.train_step(img, bbox, label, scale)\n",
    "            if ii % 100 == 0:\n",
    "                rpnloc = losses[0].cpu().data.numpy()\n",
    "                rpncls = losses[1].cpu().data.numpy()\n",
    "                roiloc = losses[2].cpu().data.numpy()\n",
    "                roicls = losses[3].cpu().data.numpy()\n",
    "                tot = losses[4].cpu().data.numpy()\n",
    "                pbar.set_description(f\"Epoch: {epoch} | Batch: {ii} | RPNLoc Loss: {rpnloc:.4f} | RPNclc Loss: {rpncls:.4f} | ROIloc Loss: {roiloc:.4f} | ROIclc Loss: {roicls:.4f} | Total Loss: {tot:.4f}\")\n",
    "            if (ii + 1) % 100 == 0:\n",
    "                if os.path.exists(opt.debug_file):\n",
    "                    ipdb.set_trace()\n",
    "\n",
    "                # plot loss\n",
    "                trainer.vis.plot_many(trainer.get_meter_data())\n",
    "\n",
    "                print(trainer.get_meter_data())\n",
    "                try:\n",
    "                    ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
    "                    gt_img = visdom_bbox(ori_img_,\n",
    "                                        at.tonumpy(bbox_[0]),\n",
    "                                        at.tonumpy(label_[0]))\n",
    "                    trainer.vis.img('gt_img', gt_img)\n",
    "                    plt.show()\n",
    "\n",
    "                    # plot predicti bboxes\n",
    "                    _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
    "                    pred_img = visdom_bbox(ori_img_,\n",
    "                                        at.tonumpy(_bboxes[0]),\n",
    "                                        at.tonumpy(_labels[0]).reshape(-1),\n",
    "                                        at.tonumpy(_scores[0]))\n",
    "                    plt.show()\n",
    "                    trainer.vis.img('pred_img', pred_img)\n",
    "\n",
    "                    # rpn confusion matrix(meter)\n",
    "                    trainer.vis.text(str(trainer.rpn_cm.value().tolist()),\n",
    "                                     win='rpn_cm')\n",
    "                    # roi confusion matrix\n",
    "                    trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf,\n",
    "                                                          False).float())\n",
    "                except:\n",
    "                    print(\"Cannot display images\")\n",
    "\n",
    "        # Save after every epoch\n",
    "        epoch_path = trainer.save(epoch, best_map=0, model_name=opt.model_name)\n",
    "                \n",
    "        eval_result = eval(val_dataloader, faster_rcnn, test_num=1000)\n",
    "        trainer.vis.plot('val_map', eval_result['map'])\n",
    "        lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "        val_log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n",
    "                                                   str(eval_result['map']),\n",
    "                                                        str(trainer.get_meter_data()))\n",
    "        trainer.vis.log(val_log_info)\n",
    "        print(\"Evaluation Results on Val Set \")\n",
    "        print(val_log_info)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        if eval_result['map'] > best_map:\n",
    "            best_map = eval_result['map']\n",
    "            best_path = epoch_path\n",
    "\n",
    "        if epoch == 9:\n",
    "            trainer.load(best_path)\n",
    "            trainer.faster_rcnn.scale_lr(opt.lr_decay)\n",
    "            lr_ = lr_ * opt.lr_decay\n",
    "\n",
    "        if epoch == 13: \n",
    "            break\n",
    "\n",
    "        test_eval_result = eval(test_dataloader, faster_rcnn, test_num=1000)\n",
    "        trainer.vis.plot('test_map', test_eval_result['map'])\n",
    "        test_lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "        test_log_info = 'lr:{}, map:{}'.format(str(test_lr_),\n",
    "                                               str(test_eval_result['map']))\n",
    "        print(\"Evaluation Results on Test Set (first 10000): \")\n",
    "        trainer.vis.log(test_log_info)\n",
    "        print(test_log_info)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: 19033 | VAL SET: 0 | TEST SET: 15019\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(opt)\n",
    "dataloader = data_.DataLoader(dataset, \\\n",
    "                            batch_size=1, \\\n",
    "                            shuffle=True, \\\n",
    "                            # pin_memory=True,\n",
    "                            num_workers=opt.num_workers)\n",
    "\n",
    "valset = TestDataset(opt, split='val')\n",
    "val_dataloader = data_.DataLoader(valset,\n",
    "                                batch_size=1,\n",
    "                                num_workers=opt.test_num_workers,\n",
    "                                shuffle=False, \\\n",
    "                                pin_memory=True\n",
    "                                )\n",
    "\n",
    "testset = TestDataset(opt, split='test')\n",
    "test_dataloader = data_.DataLoader(testset,\n",
    "                                batch_size=1,\n",
    "                                num_workers=opt.test_num_workers,\n",
    "                                shuffle=False, \\\n",
    "                                pin_memory=True\n",
    "                                )\n",
    "print(f\"TRAIN SET: {len(dataloader)} | VAL SET: {len(val_dataloader)} | TEST SET: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(opt._parse_all())\n",
    "    \n",
    "    print(\"Using Mask VGG\") if opt.mask else print(\"Using normal VGG16\")\n",
    "    faster_rcnn = FasterRCNNVGG16(mask=opt.mask)\n",
    "    print('model construct completed')\n",
    "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "    trainer.vis.text(dataset.db.label_names, win='labels')\n",
    "    best_map = 0\n",
    "    lr_ = opt.lr\n",
    "    start_epoch = 0\n",
    "\n",
    "    if opt.load_path:\n",
    "        assert os.path.isfile(opt.load_path), 'Checkpoint {} does not exist.'.format(opt.load_path)\n",
    "        checkpoint = torch.load(opt.load_path)['other_info']\n",
    "        if opt.use_simple:\n",
    "            start_epoch = 0\n",
    "            best_map = 0\n",
    "        else:\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_map = checkpoint['best_map']\n",
    "        trainer.load(opt.load_path)\n",
    "        print(\"=\"*30+\"   Checkpoint   \"+\"=\"*30)\n",
    "        print(\"Loaded checkpoint '{}' (epoch {})\".format(opt.load_path, start_epoch))\n",
    "    \n",
    "    \n",
    "    train(opt, faster_rcnn, dataloader, val_dataloader, test_dataloader, trainer, lr_,\n",
    "          best_map, start_epoch)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======user config========\n",
      "{'benchmark_path': None,\n",
      " 'caffe_pretrain': False,\n",
      " 'caffe_pretrain_path': 'checkpoints/vgg16_caffe.pth',\n",
      " 'data': 'voc',\n",
      " 'debug_file': '/tmp/debugf',\n",
      " 'env': 'faster_rcnn',\n",
      " 'epoch': 14,\n",
      " 'load_path': '/datasets/home/98/898/cjgunthe/Fast-Pedestrian-Tracking/checkpoints/fasterrcnn_12131543_0_test_run',\n",
      " 'lr': 0.001,\n",
      " 'lr_decay': 0.1,\n",
      " 'mask': True,\n",
      " 'mask_conv': False,\n",
      " 'mask_lin': True,\n",
      " 'max_size': 1000,\n",
      " 'min_size': 600,\n",
      " 'model_name': 'test_run',\n",
      " 'num_workers': 4,\n",
      " 'plot_every': 40,\n",
      " 'port': 8097,\n",
      " 'pretrained_model': 'vgg16',\n",
      " 'roi_sigma': 1.0,\n",
      " 'rpn_sigma': 3.0,\n",
      " 'sparse_dense': False,\n",
      " 'test_num': 10000,\n",
      " 'test_num_workers': 4,\n",
      " 'use_adam': True,\n",
      " 'use_chainer': False,\n",
      " 'use_drop': False,\n",
      " 'use_simple': False,\n",
      " 'voc_data_dir': '/datasets/home/98/898/cjgunthe/Fast-Pedestrian-Tracking/dataset/',\n",
      " 'weight_decay': 0.0005}\n",
      "==========end============\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-p PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /datasets/home/98/898/cjgunthe/.local/share/jupyter/runtime/kernel-b4a9dfbf-164e-453f-87f5-adb842663545.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  absolute_import\n",
    "# though cupy is not used but without this line, it raise errors...\n",
    "import cupy as cp\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.config import opt\n",
    "from data.dataset import Dataset, TestDataset, inverse_normalize\n",
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "from torch.utils import data as data_\n",
    "import torch\n",
    "from trainer import FasterRCNNTrainer\n",
    "from utils import array_tool as at\n",
    "from utils.vis_tool import vis_bbox\n",
    "from utils.eval_tool import eval_detection_voc\n",
    "\n",
    "# fix for ulimit\n",
    "# https://github.com/pytorch/pytorch/issues/973#issuecomment-346405667\n",
    "import resource\n",
    "import argparse\n",
    "\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))\n",
    "\n",
    "\n",
    "def eval(dataloader, faster_rcnn, test_num=10000):\n",
    "    print(\"\\nEVAL\")\n",
    "    pred_bboxes, pred_labels, pred_scores = list(), list(), list()\n",
    "    gt_bboxes, gt_labels = list(), list()\n",
    "    for ii, (imgs, sizes, gt_bboxes_, gt_labels_) in tqdm(enumerate(dataloader)):\n",
    "        sizes = [sizes[0][0].item(), sizes[1][0].item()]\n",
    "        pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs, [sizes])\n",
    "        gt_bboxes += list(gt_bboxes_.numpy())\n",
    "        gt_labels += list(gt_labels_.numpy())\n",
    "        pred_bboxes += pred_bboxes_\n",
    "        pred_labels += pred_labels_\n",
    "        pred_scores += pred_scores_\n",
    "        if ii == test_num: break\n",
    "\n",
    "    result = eval_detection_voc(\n",
    "        pred_bboxes, pred_labels, pred_scores,\n",
    "        gt_bboxes, gt_labels, use_07_metric=True)\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    valset = TestDataset(opt,split='val', set_id = \"set\")\n",
    "    val_dataloader = data_.DataLoader(valset,\n",
    "                                batch_size=1,\n",
    "                                num_workers=opt.test_num_workers,\n",
    "                                shuffle=True,\n",
    "                                pin_memory=True\n",
    "                                )\n",
    "    \n",
    "    testset = TestDataset(opt, split='test')\n",
    "    test_dataloader = data_.DataLoader(testset,\n",
    "                                    batch_size=1,\n",
    "                                    num_workers=opt.test_num_workers,\n",
    "                                    shuffle=False,\n",
    "                                    pin_memory=True\n",
    "                                    )\n",
    "    \n",
    "    print(f\"VAL SET: {len(val_dataloader)} | TEST SET: {len(test_dataloader)}\")\n",
    "    print(\"Using Mask VGG\") if opt.mask else print(\"Using normal VGG16\")\n",
    "    faster_rcnn = FasterRCNNVGG16(mask=opt.mask)\n",
    "    print('model construct completed')\n",
    "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "    best_map = 0\n",
    "    lr_ = opt.lr\n",
    "    \n",
    "    if args.path:\n",
    "        assert os.path.isfile(args.path), 'Checkpoint {} does not exist.'.format(args.path)\n",
    "        checkpoint = torch.load(args.path)['other_info']\n",
    "        best_map = checkpoint['best_map']\n",
    "        trainer.load(args.path)\n",
    "        \n",
    "        # if using simple-fast pretrained network, no epoch # saved\n",
    "        # if args.path == :\n",
    "        #     checkpoint['epoch'] = 0\n",
    "        #     best_map = 0\n",
    "        #\n",
    "        checkpoint['epoch'] = 0\n",
    "        print(\"=\"*30+\"   Checkpoint   \"+\"=\"*30)\n",
    "        print(\"Loaded checkpoint '{}' (epoch {})\".format(args.path, checkpoint['epoch']))\n",
    "\n",
    "        eval_result = eval(val_dataloader, faster_rcnn, test_num=1000)\n",
    "        lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "        log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_), str(eval_result['map']),\n",
    "                                                           str(trainer.get_meter_data()))\n",
    "        print(\"Evaluation Results on Validation Set: \")\n",
    "        print(log_info)\n",
    "\n",
    "\n",
    "        test_eval_result = eval(test_dataloader, faster_rcnn, test_num=1000)\n",
    "        test_lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "        test_log_info = 'lr:{}, map:{}'.format(str(test_lr_), str(test_eval_result['map']))\n",
    "        print(\"Evaluation Results on Test Set of size 1000: \")\n",
    "        print(test_log_info)\n",
    "        print(\"\\n\\n\")\n",
    "    else:\n",
    "        print(\"No checkpoint to evaluate is specified\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    print(opt._parse_all())\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
